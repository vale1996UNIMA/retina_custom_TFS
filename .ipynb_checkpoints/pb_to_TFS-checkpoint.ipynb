{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil \n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import grpc\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "from tensorflow import make_tensor_proto\n",
    "import json\n",
    "import keras_retinanet.models\n",
    "import keras_resnet\n",
    "import keras_retinanet\n",
    "import tensorflow as tf\n",
    "import shutil \n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf\n",
    "# Convert the frozen graph to TF model\n",
    "\n",
    "# Note -You need to change the outputs for your model\n",
    "# Helper for Converting Frozen graph from Disk to TF serving compatible Model\n",
    "def get_graph_def_from_file(graph_filepath):\n",
    "  tf.python.framework.ops.reset_default_graph()\n",
    "  with ops.Graph().as_default():\n",
    "    with tf.io.gfile.GFile(graph_filepath, 'rb') as f:\n",
    "      graph_def = tf.compat.v1.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      return graph_def\n",
    "\n",
    "def convert_graph_def_to_saved_model(export_dir, graph_filepath):\n",
    "  \n",
    "  graph_def = get_graph_def_from_file(graph_filepath)\n",
    "  sess = tf.compat.v1.Session(graph=ops.Graph())\n",
    "  with sess as session:\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "    tf.compat.v1.saved_model.simple_save(\n",
    "        session,\n",
    "        export_dir,\n",
    "        inputs={'input_image': session.graph.get_tensor_by_name('{}:0'.format(node.name))\n",
    "            for node in graph_def.node if node.op=='Placeholder'},\n",
    "        outputs={t:session.graph.get_tensor_by_name(t) for t in outputs}\n",
    "                        \n",
    "                \n",
    "    )\n",
    "    print('Optimized graph converted to SavedModel!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper For getting the model Size\n",
    "import os\n",
    "from tensorflow.python import ops\n",
    "def get_size(model_dir, model_file='saved_model.pb'):\n",
    "  model_file_path = os.path.join(model_dir, model_file)\n",
    "  print(model_file_path, '')\n",
    "  pb_size = os.path.getsize(model_file_path)\n",
    "  variables_size = 0\n",
    "  if os.path.exists(\n",
    "      os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
    "    variables_size = os.path.getsize(os.path.join(\n",
    "        model_dir,'variables/variables.data-00000-of-00001'))\n",
    "    variables_size += os.path.getsize(os.path.join(\n",
    "        model_dir,'variables/variables.index'))\n",
    "  print('Model size: {} KB'.format(round(pb_size/(1024.0),3)))\n",
    "  print('Variables size: {} KB'.format(round( variables_size/(1024.0),3)))\n",
    "  print('Total Size: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to change the outputs for your model\n",
    "outputs = ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0',\\\n",
    "'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0',     \\\n",
    "'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdef =get_graph_def_from_file('model_nuevos_olaf_17_nov.pb')\n",
    "convert_graph_def_to_saved_model('forTFS_17-nov', 'model_nuevos_olaf_17_nov.pb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
